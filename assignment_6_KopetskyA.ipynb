{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Develop RNN model in pytorch to solve the following problem:  \n",
    "\n",
    "1. Detect sarcasm Data from https://www.kaggle.com/sherinclaudia/sarcastic-comments-on-reddit  \n",
    "\n",
    "Your quality metric = accuracy  \n",
    "Randomly select 20% of your data for test set. You can use it only for final perfomance estimation.  \n",
    "Remember, you can use GPU resourses in kaggle kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import torch as tt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from torchtext.data import Field, LabelField, TabularDataset, Iterator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train-balanced-sarcasm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.comment.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((808618, 10), (202155, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Медиана длин комментариевв словах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median([len(x.split()) for x in df_train.comment.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('sarcasm-train.csv', index=False)\n",
    "df_test.to_csv('sarcasm-test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(x):\n",
    "    tokens = []\n",
    "    \n",
    "    for w in x:\n",
    "        token = re.sub('^[\\W]*|[\\W]*$', '', w)\n",
    "        \n",
    "        if token:\n",
    "            tokens.append(token)\n",
    "            \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(\n",
    "    sequential=True,\n",
    "    fix_length=10,\n",
    "    pad_first=True,\n",
    "    preprocessing=tokenizer,\n",
    "    batch_first=True, \n",
    "    eos_token='<eos>',\n",
    "    lower=True,\n",
    "    stop_words=STOPWORDS\n",
    ")\n",
    "\n",
    "TRAIN_LABEL = LabelField(dtype=tt.int64, use_vocab=False, preprocessing=lambda x: int(x))\n",
    "TEST_LABEL = LabelField(dtype=tt.int64, use_vocab=False, preprocessing=lambda x: int(x))\n",
    "\n",
    "\n",
    "train_dataset = TabularDataset(\n",
    "    'sarcasm-train.csv',\n",
    "     format='csv', \n",
    "     fields=[('label', TRAIN_LABEL), ('comment', TEXT)], \n",
    "     skip_header=True\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = TabularDataset(\n",
    "    'sarcasm-test.csv',\n",
    "     format='csv', \n",
    "     fields=[('label', TEST_LABEL), ('comment', TEXT)], \n",
    "     skip_header=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_dataset, min_freq=1, vectors='glove.6B.300d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTORS = TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LABEL.build_vocab(train_dataset)\n",
    "TEST_LABEL.build_vocab(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN функционал.  \n",
    "Использованная модель состоит из рекуррентного слоя, за которым следуют три полносвязных слоя.  \n",
    "При построении модели использовались и доучивались GloVe эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    train=True, \n",
    "    shuffle=True,\n",
    "    repeat=False\n",
    "):\n",
    "    dataset_iter = Iterator(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        train=train,\n",
    "        shuffle=shuffle,\n",
    "        repeat=repeat,\n",
    "        sort=False\n",
    "    )\n",
    "    \n",
    "    return dataset_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(tt.nn.Module):\n",
    "        \n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        seq_len,\n",
    "        embedding_size,\n",
    "        hidden_size,\n",
    "        vectors=None,\n",
    "        freeze_embeddings=True,\n",
    "    ):\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.seq_len = seq_len\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vectors = vectors\n",
    "        self.freeze_embeddings = freeze_embeddings\n",
    "        \n",
    "        if self.vectors is not None:\n",
    "            self.embeddings = tt.nn.Embedding.from_pretrained(self.vectors, freeze=self.freeze_embeddings)\n",
    "            \n",
    "        else:\n",
    "            self.embeddings = tt.nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "            self.embeddings.requires_grad = True\n",
    "                    \n",
    "        self.rnn = tt.nn.LSTM(\n",
    "            input_size=self.embedding_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.dense1 = tt.nn.Linear(self.hidden_size * 2, 512)\n",
    "        self.dense2 = tt.nn.Linear(512, 256)\n",
    "        self.dense3 = tt.nn.Linear(256, 128)\n",
    "        self.output_layer = tt.nn.Linear(128, 2)\n",
    "        \n",
    "        self.dropout = tt.nn.Dropout(0.15)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (tt.zeros(1, batch_size, self.hidden_size, requires_grad=True).cuda(),\n",
    "                tt.zeros(1, batch_size, self.hidden_size, requires_grad=True).cuda())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        \n",
    "        x, _hidden = self.rnn(x)\n",
    "        hidden, cell = _hidden\n",
    "        hidden = hidden.transpose(0,1)\n",
    "        cell = cell.transpose(0,1)\n",
    "        hidden = hidden.contiguous().view(hidden.size(0),-1)\n",
    "        cell = cell.contiguous().view(cell.size(0),-1)\n",
    "        x = tt.cat([hidden, cell], dim=1).squeeze(1)\n",
    "        \n",
    "        x = self.dense1(x)\n",
    "        x = tt.nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.dense2(x)\n",
    "        x = tt.nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.dense3(x)\n",
    "        x = tt.nn.functional.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    epochs,\n",
    "    model, \n",
    "    optimizer,\n",
    "    train_iterator,\n",
    "    test_iterator=None,\n",
    "    scheduler=None,\n",
    "    patience=5,\n",
    "    save_path='tt_model'\n",
    "):    \n",
    "    train_losses = []\n",
    "    test_accs = []\n",
    "    max_test_acc = 0\n",
    "    n_no_improv_epochs = 0\n",
    "    \n",
    "    criterion = tt.nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        c_train_losses = []\n",
    "        c_test_losses = []\n",
    "        \n",
    "        st_time = time()\n",
    "        \n",
    "        for batch in tqdm_notebook(train_iterator):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            pred = model.forward(batch.comment.cuda())\n",
    "            train_loss = criterion(pred, batch.label.cuda())\n",
    "            c_train_losses.append(train_loss.item())\n",
    "            \n",
    "            train_loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "        \n",
    "        c_train_loss = np.mean(c_train_losses)\n",
    "        train_losses.append(c_train_loss)\n",
    "        \n",
    "        test_acc = eval_accuracy(model, test_iterator)\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        if test_acc > max_test_acc:\n",
    "            max_test_acc = test_acc\n",
    "            n_no_improv_epochs = 0\n",
    "            tt.save(model.state_dict(), save_path)\n",
    "            \n",
    "        elif n_no_improv_epochs < patience:\n",
    "            n_no_improv_epochs += 1\n",
    "            \n",
    "        else:\n",
    "            print(f'Early stopping at epoch {epoch+1}\\nBest test accuracy: {max_test_acc:.4f}')\n",
    "            break\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        c_time = time() - st_time\n",
    "        \n",
    "        print(f'epoch: {epoch+1} \\t train_loss: {c_train_loss:.4f} \\t test_acc: {test_acc:.4f} \\t time: {c_time:.2f} s.')\n",
    "    \n",
    "    return train_losses, test_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_accuracy(model, test_iter):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with tt.no_grad():\n",
    "        for test_batch in test_iter:\n",
    "            pred = model.forward(test_batch.comment.cuda()).cpu()\n",
    "            pred = tt.nn.functional.softmax(pred, dim=1)\n",
    "            pred = pred.numpy()\n",
    "            pred = pred[:,1]\n",
    "            pred = np.where(pred > 0.5, 1, 0)\n",
    "            y_pred.extend(list(pred))\n",
    "            y_true.extend(list(test_batch.label.numpy()))\n",
    "    \n",
    "    return accuracy_score(np.array(y_true), np.array(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab.itos) \n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = get_iterator(train_dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = get_iterator(test_dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    seq_len=10,\n",
    "    embedding_size=300,\n",
    "    hidden_size=512,\n",
    "    vectors=VECTORS,\n",
    "    freeze_embeddings=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tt.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = tt.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eaa3f0ce21347848607c345b6bac3e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3159), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 \t train_loss: 0.5855 \t test_acc: 0.7047 \t time: 165.10 s.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8230c92f1a4caa824e936138032c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3159), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 \t train_loss: 0.5064 \t test_acc: 0.6945 \t time: 162.21 s.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bd554a7d314541b1d493bddf9c7778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3159), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 \t train_loss: 0.4095 \t test_acc: 0.6872 \t time: 162.20 s.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b2616aa33f4d4bb61c9fcbd99b2fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3159), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 \t train_loss: 0.3738 \t test_acc: 0.6827 \t time: 162.05 s.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a9bd0dd5ae24bd886a7953fad0f683f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3159), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 5\n",
      "Best test accuracy: 0.7047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.5855079675898139,\n",
       "  0.5064315397779411,\n",
       "  0.40946778430520603,\n",
       "  0.37377089785601225,\n",
       "  0.36532113330580834],\n",
       " [0.7046968909994806,\n",
       "  0.6945462640053425,\n",
       "  0.6872300957186317,\n",
       "  0.6827434394400337,\n",
       "  0.6821993025153966])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(10, model, optimizer, train_iter, test_iterator=test_iter, scheduler=scheduler, patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим лучшую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(tt.load('tt_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7051371472385051"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_accuracy(model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
